{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wat this note can do? \n",
    "* This not can make CSV file that summarize inferred selection coefficients\n",
    "* Selection coefficients shown here are substracted from the TF's coefficients. \n",
    "* This process should help to \n",
    "\n",
    "Flow of process: \n",
    "\n",
    "- reading selection coefficients and csv file that contains HXB2 index. \n",
    "- reading sequnce data \n",
    "- normalizing selection coefficients. \n",
    "- summarizing them in a single csv file. \n",
    "- Next, then integrate covariance matrix and numerator across multiple different rhesus macques. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"Pkg\"); import Pkg; \n",
    "ENV[\"LD_LIBRARY_PATH\"] = \"\"\n",
    "using Pkg\n",
    "using Distributed\n",
    "using DelimitedFiles\n",
    "using Distances\n",
    "using StatsBase \n",
    "using Profile    \n",
    "using Random\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using Plots\n",
    "using Printf\n",
    "using Measures\n",
    "using CSV\n",
    "#using FastaIO\n",
    "using LaTeXStrings;\n",
    "using DataFrames\n",
    "using KernelDensity\n",
    "rng = Random.MersenneTwister(1234);\n",
    "PRO = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"];\n",
    "AA_set = [\"-\", \"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\", \"*\"];\n",
    "AA2NUM = Dict(AA_set[i] => i for i in 1:length(AA_set));\n",
    "q = length(AA_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "syn_or_nonsyn_simple (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/my_HIV_data_cleanign.jl\")\n",
    "include(\"../src/non_synonymous_N-glycan.jl\") \n",
    "include(\"../src/process_HIV_mutation_for_CSV.jl\") ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH505 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010505\", \"RM5695\", \"RM6072\", \"RM6701\", \"RM6699\", \"RM6697\", \"RM6070\", \"RM6703\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N+:12, N-:97, N±:4\n",
      "N+:10, N-:47, N±:4\n",
      "N+:7, N-:63, N±:4\n",
      "N+:1, N-:15, N±:1\n",
      "N+:2, N-:16, N±:1\n",
      "N+:5, N-:43, N±:2\n",
      "N+:3, N-:38, N±:1\n",
      "N+:3, N-:21, N±:2\n"
     ]
    }
   ],
   "source": [
    "# --- Suppose the CH505's sequence has the complete set of the muations --- #\n",
    "csv_poly_CH505 = DataFrame(CSV.File( \"../mpl/aa_csv/CH505/index-703010505.csv\" ));;\n",
    "seq_TF_aa = csv_poly_CH505.TF; haxb2_TF = csv_poly_CH505.HXB2; seq_consensus_aa = csv_poly_CH505.consensus;\n",
    "for i_HRM in 1:length(fname_Human_RM)\n",
    "    # Read CSV\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH505/index-%s.csv\", fname_Human_RM[i_HRM])))\n",
    "    # Read Sequence\n",
    "    seq_poly = readdlm(@sprintf(\"../mpl/aa_seq/CH505/%s-poly.num\", fname_Human_RM[i_HRM]))\n",
    "    # Read CSV file \n",
    "    coefficients_MPL = readdlm(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH505/\"*fname_Human_RM[i_HRM]*\"-poly-AA-MPL.dat\")\n",
    "    coefficients_SL = readdlm(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH505/\"*fname_Human_RM[i_HRM]*\"-poly-AA-SL.dat\");\n",
    "\n",
    "    # Formatting sequencies and get frequency \n",
    "    seq_TF = copy(csv_poly.TF[csv_poly.polymorphic .!= \"NA\"]);\n",
    "    seq_ensemble = Int.(seq_poly[:, 3:end] .+ 1)\n",
    "    time_set = Int.(seq_poly[:, 1]);\n",
    "\n",
    "    seq_TF_num = [AA2NUM[x] for x in seq_TF];\n",
    "    L_poly = length(seq_TF_num);\n",
    "    time_unique = sort(unique(time_set))\n",
    "    n_time_unique = length(time_unique)\n",
    "    x1 = get_x1_AA(time_set, L_poly, q, seq_ensemble);\n",
    "\n",
    "    # --- Normalization --- #\n",
    "    (s_normed_MPL, s_normed_SL) = normalize_coefficient_AA(coefficients_MPL, coefficients_SL, q, L_poly, seq_TF, seq_ensemble, seq_TF_num);\n",
    "\n",
    "    # --- Formatting CSV file --- #\n",
    "    idx_sort = sortperm(vec(s_normed_MPL), rev=true)\n",
    "    i_poly_out_set = []; aa_out_set = []; \n",
    "    s_mpl_out_set = []; s_sl_out_set = [];\n",
    "    hxb2_out_set = []; tf_out_set = []; cons_out_set = []\n",
    "    mut_naive_out_set = []; # compare with TF\n",
    "    reversion_out_set = []\n",
    "    #mut_out_set = []; # consider the previous temporal state\n",
    "    date_first_detected = [];\n",
    "    freq_set = [[] for _ in 1:n_time_unique]\n",
    "    for n in 1:length(idx_sort)\n",
    "        i_raw = idx_sort[n]\n",
    "        s_mpl = s_normed_MPL[i_raw]\n",
    "        s_sl = s_normed_MPL[i_raw]\n",
    "        i_poly = Int(ceil(i_raw / q))\n",
    "\n",
    "        a_poly_num = i_raw - (i_poly-1) * q\n",
    "        a_poly = AA_set[a_poly_num]\n",
    "\n",
    "        idx_csv = (csv_poly.polymorphic .== string(i_poly))\n",
    "        i_poly_out = csv_poly.polymorphic[idx_csv][1]\n",
    "        hxb2_out = csv_poly.HXB2[idx_csv][1]\n",
    "\n",
    "        if( !( abs(s_mpl)<1e-7) )\n",
    "            tf_out = csv_poly.TF[idx_csv][1]\n",
    "            consensus_out = csv_poly.consensus[idx_csv][1]\n",
    "            date_detected = get_first_detected(time_unique, x1, i_poly, a_poly_num)\n",
    "            #@show i_poly, a_poly, i_poly_out, hxb2_out, tf_out, consensus_out, date_detected\n",
    "            if((a_poly==consensus_out) && (a_poly!=tf_out)) push!(reversion_out_set, true) else push!(reversion_out_set, false) end\n",
    "            push!(hxb2_out_set, hxb2_out)\n",
    "            push!(i_poly_out_set, i_poly)\n",
    "            push!(aa_out_set, a_poly)\n",
    "            push!(tf_out_set, tf_out)\n",
    "            push!(cons_out_set, consensus_out)\n",
    "            push!(mut_naive_out_set, @sprintf(\"%s%s%s\", tf_out, hxb2_out, a_poly))\n",
    "            push!(date_first_detected, date_detected)\n",
    "            push!(s_mpl_out_set, @sprintf(\"%.7f\", s_mpl))\n",
    "            push!(s_sl_out_set, @sprintf(\"%.7f\", s_sl))\n",
    "        \n",
    "            for i_t in 1:n_time_unique\n",
    "                push!(freq_set[i_t], @sprintf(\"%.3f\", x1[i_t, i_poly, a_poly_num]))\n",
    "            end\n",
    "        \n",
    "        end\n",
    "    end\n",
    "   \n",
    "    (glycan_plus_set, glycan_minus_set) = get_glycan_plus_minus_AA_seq(seq_TF_aa, haxb2_TF, hxb2_out_set, aa_out_set)\n",
    "    @printf(\"N+:%d, N-:%d, N±:%d\\n\", count(glycan_plus_set), count(glycan_minus_set), count(glycan_plus_set .* glycan_minus_set))\n",
    "    (V1_set_temp, V2_set_temp, V3_set_temp, V4_set_temp, V5_set_temp, LD_set_temp, CD4BS_set_temp) = get_variable_site_true_false(hxb2_out_set)\n",
    "    \n",
    "    df = DataFrame(\n",
    "        HXB2=hxb2_out_set, \n",
    "        polymorphic=i_poly_out_set, \n",
    "        PRO=aa_out_set, \n",
    "        TF=tf_out_set,\n",
    "        consensus=cons_out_set,\n",
    "        reversion=reversion_out_set,\n",
    "        mutation=mut_naive_out_set, \n",
    "        date=date_first_detected,\n",
    "        V1=V1_set_temp,\n",
    "        V2=V2_set_temp,\n",
    "        V3=V3_set_temp,\n",
    "        V4=V4_set_temp,\n",
    "        V5=V5_set_temp,\n",
    "        LD=LD_set_temp,\n",
    "        CD4BS=CD4BS_set_temp,\n",
    "        glycan_plus=glycan_plus_set, \n",
    "        glycan_minus=glycan_minus_set, \n",
    "        s_MPL=s_mpl_out_set, \n",
    "        s_SL=s_sl_out_set, \n",
    "    )\n",
    "    for i_t in 1:n_time_unique \n",
    "        df[!, @sprintf(\"f_at_%s\", time_unique[i_t])] = freq_set[i_t]\n",
    "    end\n",
    "\n",
    "\n",
    "    CSV.write(@sprintf(\"../mpl/aa_csv/CH505/%s-poly.csv\", fname_Human_RM[i_HRM]), df);\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH848 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010848\", \"RM6163\", \"RM6167\", \"RM6700\", \"RM6713\", \"RM6714\", \"RM6720\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N+:24, N-:227, N±:5\n",
      "N+:7, N-:54, N±:3\n",
      "N+:12, N-:79, N±:3\n",
      "N+:11, N-:90, N±:3\n",
      "N+:8, N-:39, N±:2\n",
      "N+:8, N-:61, N±:3\n",
      "N+:5, N-:36, N±:1\n"
     ]
    }
   ],
   "source": [
    "csv_poly_CH848 = DataFrame(CSV.File( \"../mpl/aa_csv/CH848/index-703010848.csv\" ));;\n",
    "seq_TF_aa = csv_poly_CH848.TF; haxb2_TF = csv_poly_CH848.HXB2; seq_consensus_aa = csv_poly_CH848.consensus;\n",
    "\n",
    "for i_HRM in 1:length(fname_Human_RM)\n",
    "    # Read CSV\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH848/index-%s.csv\", fname_Human_RM[i_HRM])))\n",
    "    # Read Sequence\n",
    "    seq_poly = readdlm(@sprintf(\"../mpl/aa_out/CH848/%s-poly.num\", fname_Human_RM[i_HRM]))\n",
    "    # Read CSV file \n",
    "    coefficients_MPL = readdlm(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH848/\"*fname_Human_RM[i_HRM]*\"-poly-AA-MPL.dat\")\n",
    "    coefficients_SL = readdlm(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH848/\"*fname_Human_RM[i_HRM]*\"-poly-AA-SL.dat\");\n",
    "\n",
    "    # Formatting sequencies and get frequency \n",
    "    seq_TF = copy(csv_poly.TF[csv_poly.polymorphic .!= \"NA\"]);\n",
    "    seq_ensemble = Int.(seq_poly[:, 3:end] .+ 1)\n",
    "    time_set = Int.(seq_poly[:, 1]);\n",
    "\n",
    "    seq_TF_num = [AA2NUM[x] for x in seq_TF];\n",
    "    L_poly = length(seq_TF_num);\n",
    "    time_unique = sort(unique(time_set))\n",
    "    n_time_unique = length(time_unique)\n",
    "    x1 = get_x1_AA(time_set, L_poly, q, seq_ensemble);\n",
    "\n",
    "    # --- Normalization --- #\n",
    "    (s_normed_MPL, s_normed_SL) = normalize_coefficient_AA(coefficients_MPL, coefficients_SL, q, L_poly, seq_TF, seq_ensemble, seq_TF_num);\n",
    "\n",
    "    # --- Formatting CSV file --- #\n",
    "    idx_sort = sortperm(vec(s_normed_MPL), rev=true)\n",
    "    i_poly_out_set = []; aa_out_set = []; \n",
    "    s_mpl_out_set = []; s_sl_out_set = [];\n",
    "    hxb2_out_set = []; tf_out_set = []; cons_out_set = []\n",
    "    mut_naive_out_set = []; # compare with TF\n",
    "    reversion_out_set = []\n",
    "    #mut_out_set = []; # consider the previous temporal state\n",
    "    date_first_detected = [];\n",
    "    freq_set = [[] for _ in 1:n_time_unique]\n",
    "    for n in 1:length(idx_sort)\n",
    "        i_raw = idx_sort[n]\n",
    "        s_mpl = s_normed_MPL[i_raw]\n",
    "        s_sl = s_normed_MPL[i_raw]\n",
    "        i_poly = Int(ceil(i_raw/ q))\n",
    "\n",
    "        a_poly_num = i_raw - (i_poly-1)*q\n",
    "        a_poly = AA_set[a_poly_num]\n",
    "\n",
    "        idx_csv = (csv_poly.polymorphic .== string(i_poly))\n",
    "        i_poly_out = csv_poly.polymorphic[idx_csv][1]\n",
    "        hxb2_out = csv_poly.HXB2[idx_csv][1]\n",
    "\n",
    "        if( !( abs(s_mpl)<1e-7) )\n",
    "\n",
    "            tf_out = csv_poly.TF[idx_csv][1]\n",
    "            consensus_out = csv_poly.consensus[idx_csv][1]\n",
    "            date_detected = get_first_detected(time_unique, x1, i_poly, a_poly_num)\n",
    "            if((a_poly==consensus_out) && (a_poly!=tf_out)) push!(reversion_out_set, true) else push!(reversion_out_set, false) end\n",
    "            #@show i_poly, a_poly, i_poly_out, hxb2_out, tf_out, consensus_out, date_detected\n",
    "            push!(hxb2_out_set, hxb2_out)\n",
    "            push!(i_poly_out_set, i_poly)\n",
    "            push!(aa_out_set, a_poly)\n",
    "            push!(tf_out_set, tf_out)\n",
    "            push!(cons_out_set, consensus_out)\n",
    "            push!(mut_naive_out_set, @sprintf(\"%s%s%s\", tf_out, hxb2_out, a_poly))\n",
    "            push!(date_first_detected, date_detected)\n",
    "            push!(s_mpl_out_set, @sprintf(\"%.7f\", s_mpl))\n",
    "            push!(s_sl_out_set, @sprintf(\"%.7f\", s_sl))\n",
    "        \n",
    "            for i_t in 1:n_time_unique\n",
    "                push!(freq_set[i_t], @sprintf(\"%.3f\", x1[i_t, i_poly, a_poly_num]))\n",
    "            end\n",
    "        \n",
    "        end\n",
    "    end\n",
    "    (glycan_plus_set, glycan_minus_set) = get_glycan_plus_minus_AA_seq(seq_TF_aa, haxb2_TF, hxb2_out_set, aa_out_set)\n",
    "    @printf(\"N+:%d, N-:%d, N±:%d\\n\", count(glycan_plus_set), count(glycan_minus_set), count(glycan_plus_set .* glycan_minus_set))\n",
    "    (V1_set_temp, V2_set_temp, V3_set_temp, V4_set_temp, V5_set_temp, LD_set_temp, CD4BS_set_temp) = get_variable_site_true_false(hxb2_out_set)\n",
    "    df = DataFrame(\n",
    "        HXB2=hxb2_out_set, \n",
    "        polymorphic=i_poly_out_set, \n",
    "        PRO=aa_out_set, \n",
    "        TF=tf_out_set,\n",
    "        consensus=cons_out_set,\n",
    "        reversion=reversion_out_set,\n",
    "        mutation=mut_naive_out_set, \n",
    "        date=date_first_detected,\n",
    "        V1=V1_set_temp,\n",
    "        V2=V2_set_temp,\n",
    "        V3=V3_set_temp,\n",
    "        V4=V4_set_temp,\n",
    "        V5=V5_set_temp,\n",
    "        LD=LD_set_temp,\n",
    "        CD4BS=CD4BS_set_temp,\n",
    "        glycan_plus=glycan_plus_set, \n",
    "        glycan_minus=glycan_minus_set, \n",
    "        s_MPL=s_mpl_out_set, \n",
    "        s_SL=s_sl_out_set, \n",
    "    )\n",
    "\n",
    "    for i_t in 1:n_time_unique \n",
    "        df[!, @sprintf(\"f_at_%s\", time_unique[i_t])] = freq_set[i_t]\n",
    "    end\n",
    "    CSV.write(@sprintf(\"../mpl/aa_csv/CH848/%s-poly.csv\", fname_Human_RM[i_HRM]), df);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginalizing covariance and numerator; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH505 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010505\", \"RM5695\", \"RM6072\", \"RM6701\", \"RM6699\", \"RM6697\", \"RM6070\", \"RM6703\"];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_HRM = 2\n",
    "csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH505/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "cov_raw = readdlm(@sprintf(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH505/covariance-%s-poly-AA.dat\", fname_Human_RM[i_HRM]))\n",
    "num_raw = readdlm(@sprintf(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH505/numerator-%s-poly-AA.dat\", fname_Human_RM[i_HRM]));\n",
    "coefficients_MPL = readdlm(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH505/\"*fname_Human_RM[i_HRM]*\"-poly-AA-MPL.dat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes 283.425596 sec.\n",
    "#γ = 10 ;\n",
    "#@time s_temp = (cov_raw + γ*I) \\ num_raw;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define HXB2 set that are appeared on RMs at least once --- #\n",
    "HXB2_set = []\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH505/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    for x in csv_poly.HXB2\n",
    "        if(x ∉ HXB2_set )\n",
    "            push!(HXB2_set, x)\n",
    "        end\n",
    "    end\n",
    "end;\n",
    "\n",
    "HXB2_set = copy(unique(HXB2_set));\n",
    "\n",
    "# --- Set global \"polymorphic\" indicies across multiple RMs --- #\n",
    "indicator_poly_set = [false for _ in HXB2_set];\n",
    "TF_set = [\"-\" for _ in HXB2_set]\n",
    "# A function that maps polymorphic index in RM to another \"polymorphic of RMs\"\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH505/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    non_NA_sites = csv_poly.HXB2[csv_poly.polymorphic .!= \"NA\"]\n",
    "    for i in 1:length(HXB2_set)\n",
    "        hxb2 = HXB2_set[i]\n",
    "        if(hxb2 ∈ non_NA_sites)\n",
    "            indicator_poly_set[i] = true\n",
    "        end\n",
    "    end    \n",
    "  \n",
    "end\n",
    "poly_set = [\"NA\" for _ in HXB2_set];\n",
    "L_RM = count(indicator_poly_set)\n",
    "poly_set[indicator_poly_set] = string.(collect(1:L_RM));\n",
    "\n",
    "# ------ make mapping between individual poly indicies to marginalized poly indicies ----- #;\n",
    "HXB2_poly = HXB2_set[indicator_poly_set];\n",
    "poly2poly_map = [[] for _ in 1:length(fname_Human_RM)]\n",
    "num_set_temp = collect(1:length(HXB2_poly))\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH505/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    # --- Get indecies set that maps inidividual polymorphic sites to global polymorphic sites. --- #\n",
    "    for x in csv_poly.HXB2[csv_poly.polymorphic .!= \"NA\"];\n",
    "        idx = num_set_temp[HXB2_poly .== x]\n",
    "        push!(poly2poly_map[i_HRM], idx[1])\n",
    "    end;\n",
    "end\n",
    "# ----- Just for obtaining TF and aonsenssus----- #\n",
    "TF_RMs_set = [\"NA\" for _ in HXB2_set]\n",
    "consensus_RMs_set = [\"NA\" for _ in HXB2_set]\n",
    "num_temp = collect(1:length(HXB2_set))\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH505/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    \n",
    "    for k in 1:length(csv_poly.HXB2)\n",
    "        if(csv_poly.polymorphic[k] != \"NA\")\n",
    "            hxb2 = csv_poly.HXB2[k]\n",
    "            idx = HXB2_set .== hxb2\n",
    "            TF_RMs_set[num_temp[idx][1]] = string(csv_poly.TF[k][1])\n",
    "            consensus_RMs_set[num_temp[idx][1]] = string(csv_poly.consensus[k][1])\n",
    "        end \n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Marginalizing cov and num ---- #\n",
    "cov_RM = zeros(q*L_RM, q*L_RM)\n",
    "num_RM = zeros(q*L_RM);\n",
    "\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    cov_raw = readdlm(@sprintf(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH505/covariance-%s-poly-AA.dat\", fname_Human_RM[i_HRM]))\n",
    "    num_raw = readdlm(@sprintf(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH505/numerator-%s-poly-AA.dat\", fname_Human_RM[i_HRM]));\n",
    "    poly_idx = copy(poly2poly_map[i_HRM]);\n",
    "    @assert length(num_raw) == q*length(poly_idx)\n",
    "    for i in 1:length(poly_idx)\n",
    "        i_poly = poly_idx[i]\n",
    "        num_RM[km.(i_poly, 1:q, q)] += num_raw[km.(i, 1:q, q)]\n",
    "        for j in 1:length(poly_idx)\n",
    "            j_poly = poly_idx[j]\n",
    "            cov_RM[km.(i_poly, 1:q, q), km.(j_poly, 1:q, q)] += cov_raw[km.(i, 1:q, q), km.(j, 1:q, q)]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# ----- Write out integrated cov and num to CSV files ----- #\n",
    "fout_num = open(\"../mpl/aa_out/CH505/numerator-RMs-poly-AA.dat\", \"w\")\n",
    "for x in num_RM\n",
    "    println(fout_num, x)\n",
    "end\n",
    "close(fout_num)\n",
    "\n",
    "fout_cov = open(\"../mpl/aa_out/CH505/covariance-RMs-poly-AA.dat\", \"w\")\n",
    "for i in 1:size(cov_RM,1)\n",
    "    println(fout_cov, @sprintf(\"%s\", join(cov_RM[i, :], \" \")))\n",
    "end\n",
    "close(fout_cov);\n",
    "\n",
    "df = DataFrame(\n",
    "        HXB2=HXB2_set, \n",
    "        polymorphic=poly_set, \n",
    "        TF=TF_RMs_set, \n",
    "        consensus=consensus_RMs_set)\n",
    "CSV.write(\"../mpl/aa_csv/CH505/index-RMs-poly.csv\", df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25.037920 seconds (9 allocations: 1.506 GiB, 0.03% gc time)\n",
      "  0.005806 seconds (9 allocations: 157.375 KiB)\n"
     ]
    }
   ],
   "source": [
    "γ = 10\n",
    "@time s_MPL_RM = (cov_RM + γ*I) \\ num_RM;\n",
    "@time s_SL_RM =  num_RM ./ (cov_RM[diagind(cov_RM)] .+ γ);\n",
    "\n",
    "fout_mpl = open(\"../mpl/aa_out/CH505/RMs-poly-AA-MPL.dat\", \"w\")\n",
    "fout_sl = open(\"../mpl/aa_out/CH505/RMs-poly-AA-SL.dat\", \"w\")\n",
    "for x in s_MPL_RM\n",
    "    println(fout_mpl, x)\n",
    "end\n",
    "close(fout_mpl)\n",
    "#\n",
    "for x in s_SL_RM\n",
    "    println(fout_sl, x)\n",
    "end\n",
    "close(fout_sl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH848 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010505\", \"RM6163\", \"RM6167\", \"RM6700\", \"RM6713\", \"RM6714\", \"RM6720\" ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define HXB2 set that are appeared on RMs at least once --- #\n",
    "HXB2_set = []\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH848/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    for x in csv_poly.HXB2\n",
    "        if(x ∉ HXB2_set )\n",
    "            push!(HXB2_set, x)\n",
    "        end\n",
    "    end\n",
    "end;\n",
    "\n",
    "HXB2_set = copy(unique(HXB2_set));\n",
    "\n",
    "# --- Set global \"polymorphic\" indicies across multiple RMs --- #\n",
    "indicator_poly_set = [false for _ in HXB2_set];\n",
    "TF_set = [\"-\" for _ in HXB2_set]\n",
    "# A function that maps polymorphic index in RM to another \"polymorphic of RMs\"\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH848/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    non_NA_sites = csv_poly.HXB2[csv_poly.polymorphic .!= \"NA\"]\n",
    "    for i in 1:length(HXB2_set)\n",
    "        hxb2 = HXB2_set[i]\n",
    "        if(hxb2 ∈ non_NA_sites)\n",
    "            indicator_poly_set[i] = true\n",
    "        end\n",
    "    end    \n",
    "  \n",
    "end\n",
    "poly_set = [\"NA\" for _ in HXB2_set];\n",
    "L_RM = count(indicator_poly_set)\n",
    "poly_set[indicator_poly_set] = string.(collect(1:L_RM));\n",
    "\n",
    "# ------ make mapping between individual poly indicies to marginalized poly indicies ----- #;\n",
    "HXB2_poly = HXB2_set[indicator_poly_set];\n",
    "poly2poly_map = [[] for _ in 1:length(fname_Human_RM)]\n",
    "num_set_temp = collect(1:length(HXB2_poly))\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH848/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    # --- Get indecies set that maps inidividual polymorphic sites to global polymorphic sites. --- #\n",
    "    for x in csv_poly.HXB2[csv_poly.polymorphic .!= \"NA\"];\n",
    "        idx = num_set_temp[HXB2_poly .== x]\n",
    "        push!(poly2poly_map[i_HRM], idx[1])\n",
    "    end;\n",
    "end\n",
    "# ----- Just for obtaining TF and aonsenssus----- #\n",
    "TF_RMs_set = [\"NA\" for _ in HXB2_set]\n",
    "consensus_RMs_set = [\"NA\" for _ in HXB2_set]\n",
    "num_temp = collect(1:length(HXB2_set))\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    csv_poly = DataFrame(CSV.File(@sprintf(\"../mpl/aa_csv/CH848/index-%s.csv\", fname_Human_RM[i_HRM])));\n",
    "    \n",
    "    for k in 1:length(csv_poly.HXB2)\n",
    "        if(csv_poly.polymorphic[k] != \"NA\")\n",
    "            hxb2 = csv_poly.HXB2[k]\n",
    "            idx = HXB2_set .== hxb2\n",
    "            TF_RMs_set[num_temp[idx][1]] = string(csv_poly.TF[k][1])\n",
    "            consensus_RMs_set[num_temp[idx][1]] = string(csv_poly.consensus[k][1])\n",
    "        end \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Marginalizing cov and num ---- #\n",
    "cov_RM = zeros(q*L_RM, q*L_RM)\n",
    "num_RM = zeros(q*L_RM);\n",
    "\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    cov_raw = readdlm(@sprintf(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH848/covariance-%s-poly-AA.dat\", fname_Human_RM[i_HRM]))\n",
    "    num_raw = readdlm(@sprintf(\"/net/dali/home/barton/kais/MPL_AA_rhesus/HIV/CH848/numerator-%s-poly-AA.dat\", fname_Human_RM[i_HRM]));\n",
    "    poly_idx = copy(poly2poly_map[i_HRM]);\n",
    "    @assert length(num_raw) == q*length(poly_idx)\n",
    "    for i in 1:length(poly_idx)\n",
    "        i_poly = poly_idx[i]\n",
    "        num_RM[km.(i_poly, 1:q, q)] += num_raw[km.(i, 1:q, q)]\n",
    "        for j in 1:length(poly_idx)\n",
    "            j_poly = poly_idx[j]\n",
    "            cov_RM[km.(i_poly, 1:q, q), km.(j_poly, 1:q, q)] += cov_raw[km.(i, 1:q, q), km.(j, 1:q, q)]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# ----- Write out integrated cov and num to CSV files ----- #\n",
    "fout_num = open(\"../mpl/aa_out/CH848/numerator-RMs-poly-AA.dat\", \"w\")\n",
    "for x in num_RM\n",
    "    println(fout_num, x)\n",
    "end\n",
    "close(fout_num)\n",
    "\n",
    "fout_cov = open(\"../mpl/aa_out/CH848/covariance-RMs-poly-AA.dat\", \"w\")\n",
    "for i in 1:size(cov_RM,1)\n",
    "    println(fout_cov, @sprintf(\"%s\", join(cov_RM[i, :], \" \")))\n",
    "end\n",
    "close(fout_cov);\n",
    "\n",
    "# --- I need to include V1-V5, CD4, LD, Glycan alter.\n",
    "# --> To compute the glycan I need to fix the TF sequence then identify the \n",
    "# consider to use the function. \n",
    "df = DataFrame(\n",
    "        HXB2=HXB2_set, \n",
    "        polymorphic=poly_set, \n",
    "        TF=TF_RMs_set, \n",
    "        consensus=consensus_RMs_set\n",
    "    )\n",
    "\n",
    "CSV.write(\"../mpl/aa_csv/CH848/index-RMs-poly.csv\", df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25.524340 seconds (9 allocations: 1.669 GiB, 0.26% gc time)\n",
      "  0.000484 seconds (9 allocations: 165.625 KiB)\n"
     ]
    }
   ],
   "source": [
    "γ = 10\n",
    "@time s_MPL_RM = (cov_RM + γ*I) \\ num_RM;\n",
    "@time s_SL_RM =  num_RM ./ (cov_RM[diagind(cov_RM)] .+ γ);\n",
    "\n",
    "fout_mpl = open(\"../mpl/aa_out/CH848/RMs-poly-AA-MPL.dat\", \"w\")\n",
    "fout_sl = open(\"../mpl/aa_out/CH848/RMs-poly-AA-SL.dat\", \"w\")\n",
    "for x in s_MPL_RM\n",
    "    println(fout_mpl, x)\n",
    "end\n",
    "close(fout_mpl)\n",
    "#\n",
    "for x in s_SL_RM\n",
    "    println(fout_sl, x)\n",
    "end\n",
    "close(fout_sl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making CSV for marginalized RMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010505\", \"RM5695\", \"RM6072\", \"RM6701\", \"RM6699\", \"RM6697\", \"RM6070\", \"RM6703\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_poly = DataFrame(CSV.File(\"../mpl/aa_csv/CH505/index-RMs-poly.csv\"))\n",
    "# Read CSV file \n",
    "coefficients_MPL = readdlm(\"../mpl/aa_out/CH505/RMs-poly-AA-MPL.dat\")\n",
    "coefficients_SL = readdlm(\"../mpl/aa_out/CH505/RMs-poly-AA-SL.dat\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting sequencies and get frequency \n",
    "seq_TF = copy(csv_poly.TF[csv_poly.polymorphic .!= \"NA\"]);\n",
    "seq_TF_num = [AA2NUM[x] for x in seq_TF];\n",
    "L_poly = length(seq_TF_num)\n",
    "# --- Normalization --- #\n",
    "(s_normed_MPL, s_normed_SL) = normalize_coefficient_AA(coefficients_MPL, coefficients_SL, q, L_poly, seq_TF, seq_TF_num)\n",
    "# --- Formatting CSV file --- #\n",
    "idx_sort = sortperm(vec(s_normed_MPL), rev=true)\n",
    "\n",
    "i_poly_out_set = []; aa_out_set = []; \n",
    "s_mpl_out_set = []; s_sl_out_set = [];\n",
    "hxb2_out_set = []; tf_out_set = []; cons_out_set = []\n",
    "mut_naive_out_set = []; # compare with TF\n",
    "\n",
    "for n in 1:length(idx_sort)\n",
    "    i_raw = idx_sort[n]\n",
    "    s_mpl = s_normed_MPL[i_raw]\n",
    "    s_sl = s_normed_MPL[i_raw]\n",
    "    i_poly = Int(ceil(i_raw/ q))\n",
    "\n",
    "    a_poly_num = i_raw - (i_poly-1)*q\n",
    "    a_poly = AA_set[a_poly_num]\n",
    "\n",
    "    idx_csv = (csv_poly.polymorphic .== string(i_poly))\n",
    "    i_poly_out = csv_poly.polymorphic[idx_csv][1]\n",
    "    hxb2_out = csv_poly.HXB2[idx_csv][1]\n",
    "\n",
    "    if( !( abs(s_mpl)<1e-7) )\n",
    "        tf_out = csv_poly.TF[idx_csv][1]\n",
    "        consensus_out = csv_poly.consensus[idx_csv][1]\n",
    "        push!(hxb2_out_set, hxb2_out)\n",
    "        push!(i_poly_out_set, i_poly)\n",
    "        push!(aa_out_set, a_poly)\n",
    "        push!(tf_out_set, tf_out)\n",
    "        push!(cons_out_set, consensus_out)\n",
    "        push!(mut_naive_out_set, @sprintf(\"%s%s%s\", tf_out, hxb2_out, a_poly))\n",
    "        push!(s_mpl_out_set, @sprintf(\"%.7f\", s_mpl))\n",
    "        push!(s_sl_out_set, @sprintf(\"%.7f\", s_sl))        \n",
    "    end\n",
    "end\n",
    "\n",
    "df = DataFrame(\n",
    "    HXB2=hxb2_out_set, \n",
    "    polymorphic=i_poly_out_set, \n",
    "    PRO=aa_out_set, \n",
    "    TF=tf_out_set,\n",
    "    consensus=cons_out_set,\n",
    "    mutation=mut_naive_out_set, \n",
    "    s_MPL=s_mpl_out_set, \n",
    "    s_SL=s_sl_out_set, \n",
    ")\n",
    "CSV.write(\"../mpl/aa_csv/CH505/RMs-poly.csv\", df);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010505\", \"RM6163\", \"RM6167\", \"RM6700\", \"RM6713\", \"RM6714\", \"RM6720\" ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_poly = DataFrame(CSV.File(\"../mpl/aa_csv/CH848/index-RMs-poly.csv\"))\n",
    "# Read CSV file \n",
    "coefficients_MPL = readdlm(\"../mpl/aa_out/CH848/RMs-poly-AA-MPL.dat\")\n",
    "coefficients_SL = readdlm(\"../mpl/aa_out/CH848/RMs-poly-AA-SL.dat\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting sequencies and get frequency \n",
    "seq_TF = copy(csv_poly.TF[csv_poly.polymorphic .!= \"NA\"]);\n",
    "seq_TF_num = [AA2NUM[x] for x in seq_TF];\n",
    "L_poly = length(seq_TF_num)\n",
    "# --- Normalization --- #\n",
    "(s_normed_MPL, s_normed_SL) = normalize_coefficient_AA(coefficients_MPL, coefficients_SL, q, L_poly, seq_TF, seq_TF_num)\n",
    "# --- Formatting CSV file --- #\n",
    "idx_sort = sortperm(vec(s_normed_MPL), rev=true)\n",
    "\n",
    "i_poly_out_set = []; aa_out_set = []; \n",
    "s_mpl_out_set = []; s_sl_out_set = [];\n",
    "hxb2_out_set = []; tf_out_set = []; cons_out_set = []\n",
    "mut_naive_out_set = []; # compare with TF\n",
    "\n",
    "for n in 1:length(idx_sort)\n",
    "    i_raw = idx_sort[n]\n",
    "    s_mpl = s_normed_MPL[i_raw]\n",
    "    s_sl = s_normed_MPL[i_raw]\n",
    "    i_poly = Int(ceil(i_raw/ q))\n",
    "\n",
    "    a_poly_num = i_raw - (i_poly-1)*q\n",
    "    a_poly = AA_set[a_poly_num]\n",
    "\n",
    "    idx_csv = (csv_poly.polymorphic .== string(i_poly))\n",
    "    i_poly_out = csv_poly.polymorphic[idx_csv][1]\n",
    "    hxb2_out = csv_poly.HXB2[idx_csv][1]\n",
    "\n",
    "    if( !( abs(s_mpl)<1e-7) )\n",
    "        tf_out = csv_poly.TF[idx_csv][1]\n",
    "        consensus_out = csv_poly.consensus[idx_csv][1]\n",
    "        push!(hxb2_out_set, hxb2_out)\n",
    "        push!(i_poly_out_set, i_poly)\n",
    "        push!(aa_out_set, a_poly)\n",
    "        push!(tf_out_set, tf_out)\n",
    "        push!(cons_out_set, consensus_out)\n",
    "        push!(mut_naive_out_set, @sprintf(\"%s%s%s\", tf_out, hxb2_out, a_poly))\n",
    "        push!(s_mpl_out_set, @sprintf(\"%.7f\", s_mpl))\n",
    "        push!(s_sl_out_set, @sprintf(\"%.7f\", s_sl))        \n",
    "    end\n",
    "end\n",
    "\n",
    "df = DataFrame(\n",
    "    HXB2=hxb2_out_set, \n",
    "    polymorphic=i_poly_out_set, \n",
    "    PRO=aa_out_set, \n",
    "    TF=tf_out_set,\n",
    "    consensus=cons_out_set,\n",
    "    mutation=mut_naive_out_set, \n",
    "    s_MPL=s_mpl_out_set, \n",
    "    s_SL=s_sl_out_set, \n",
    ")\n",
    "CSV.write(\"../mpl/aa_csv/CH848/RMs-poly.csv\", df);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute enrichment ratio for macaques and make a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHIV.CH505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010505\", \"RM5695\", \"RM6072\", \"RM6701\", \"RM6699\", \"RM6697\", \"RM6070\", \"RM6703\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname_in = \"../mpl/aa_csv/CH505/RM5695-poly.csv\"\n",
      "N+:10, N-:47, N±:4\n",
      "fname_in = \"../mpl/aa_csv/CH505/RM6072-poly.csv\"\n",
      "N+:7, N-:63, N±:4\n",
      "fname_in = \"../mpl/aa_csv/CH505/RM6701-poly.csv\"\n",
      "N+:1, N-:15, N±:1\n",
      "fname_in = \"../mpl/aa_csv/CH505/RM6699-poly.csv\"\n",
      "N+:2, N-:16, N±:1\n",
      "fname_in = \"../mpl/aa_csv/CH505/RM6697-poly.csv\"\n",
      "N+:5, N-:43, N±:2\n",
      "fname_in = \"../mpl/aa_csv/CH505/RM6070-poly.csv\"\n",
      "N+:3, N-:38, N±:1\n",
      "fname_in = \"../mpl/aa_csv/CH505/RM6703-poly.csv\"\n",
      "N+:3, N-:21, N±:2\n"
     ]
    }
   ],
   "source": [
    "list_set_HXB2 = []; list_set_s_MPL = []; list_set_date = []; list_set_mutation = []; list_set_reversion = []; list_set_RMs = []\n",
    "list_set_N_plus = []; list_set_N_minus = []; list_set_N_shift = [];\n",
    "list_set_V1 = []; list_set_V2 = []; list_set_V3 = []; list_set_V4 = []; list_set_V5 = []; list_set_LD = []; list_set_CD4BS = []\n",
    "list_set_PRO = [] # This is protein but for the sake of consistency, I referr this nucleotide.\n",
    "#i_HRM = 2\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "#for i_HRM in 2:2\n",
    "    fname_in = @sprintf(\"../mpl/aa_csv/CH505/%s-poly.csv\", fname_Human_RM[i_HRM])\n",
    "    csv_poly = DataFrame(CSV.File( fname_in));\n",
    "    @show fname_in\n",
    "    append!(list_set_HXB2, copy(csv_poly.HXB2))\n",
    "    append!(list_set_PRO, copy(csv_poly.PRO))\n",
    "    append!(list_set_date, copy(csv_poly.date))\n",
    "    append!(list_set_mutation, copy(csv_poly.mutation))\n",
    "    append!(list_set_reversion, copy(csv_poly.reversion))\n",
    "    append!(list_set_RMs, [fname_Human_RM[i_HRM] for _ in 1:length(csv_poly.HXB2)] )\n",
    "    append!(list_set_s_MPL, copy(csv_poly.s_MPL))\n",
    "    @printf(\"N+:%d, N-:%d, N±:%d\\n\", count(csv_poly.glycan_plus), count(csv_poly.glycan_minus), count(csv_poly.glycan_minus .* csv_poly.glycan_plus))\n",
    "    glycan_plus_temp = zeros(length(csv_poly.glycan_plus)); glycan_plus_temp[csv_poly.glycan_plus] .= 1\n",
    "    glycan_minus_temp = zeros(length(csv_poly.glycan_minus)); glycan_minus_temp[csv_poly.glycan_minus] .= 1\n",
    "    glycan_shift_temp = zeros(length(csv_poly.glycan_plus)); glycan_shift_temp[csv_poly.glycan_plus .* csv_poly.glycan_minus] .= 1\n",
    "    append!(list_set_N_plus, copy(glycan_plus_temp))\n",
    "    append!(list_set_N_minus, copy(glycan_minus_temp))\n",
    "    append!(list_set_N_shift, copy(glycan_shift_temp))\n",
    "    append!(list_set_CD4BS, copy(csv_poly.CD4BS))\n",
    "    append!(list_set_LD, copy(csv_poly.LD))\n",
    "    append!(list_set_V1, copy(csv_poly.V1))\n",
    "    append!(list_set_V2, copy(csv_poly.V2))\n",
    "    append!(list_set_V3, copy(csv_poly.V3))\n",
    "    append!(list_set_V4, copy(csv_poly.V4))\n",
    "    append!(list_set_V5, copy(csv_poly.V5));\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort selection coefficients.\n",
    "sort_indx = sortperm(list_set_s_MPL, rev=true);\n",
    "\n",
    "df = DataFrame(\n",
    "    HXB2_index = list_set_HXB2[sort_indx], \n",
    "    RM = list_set_RMs[sort_indx], \n",
    "    reversion = list_set_reversion[sort_indx], \n",
    "    mutation = list_set_mutation[sort_indx], \n",
    "    PRO = list_set_PRO[sort_indx],\n",
    "    date = list_set_date[sort_indx], \n",
    "    s_MPL = list_set_s_MPL[sort_indx], \n",
    "    N_linked_glycan_plus_fr3 = list_set_N_plus[sort_indx], \n",
    "    N_linked_glycan_minus_fr3 = list_set_N_minus[sort_indx], \n",
    "    N_linked_glycan_shift_fr3 = list_set_N_shift[sort_indx], \n",
    "    LoopD = list_set_LD[sort_indx], \n",
    "    V1 = list_set_V1[sort_indx], \n",
    "    V2 = list_set_V2[sort_indx], \n",
    "    V3 = list_set_V3[sort_indx], \n",
    "    V4 = list_set_V4[sort_indx], \n",
    "    V5 = list_set_V5[sort_indx], \n",
    "    # The following is just copying other result to avoid error due to the absent of the process\n",
    "    CD4BS = list_set_CD4BS[sort_indx], \n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"../out/summary-RMs-AA_CH505.csv\", df); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHIV.CH848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Human_RM = [\"703010505\", \"RM6163\", \"RM6167\", \"RM6700\", \"RM6713\", \"RM6714\", \"RM6720\" ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_set_HXB2 = []; list_set_s_MPL = []; list_set_date = []; list_set_mutation = []; list_set_reversion = []; list_set_RMs = []\n",
    "list_set_N_plus = []; list_set_N_minus = []; list_set_N_shift = [];\n",
    "list_set_V1 = []; list_set_V2 = []; list_set_V3 = []; list_set_V4 = []; list_set_V5 = []; list_set_LD = []; list_set_CD4BS = []\n",
    "list_set_PRO = [] # This is protein but for the sake of consistency, I referr this nucleotide.\n",
    "#i_HRM = 2\n",
    "for i_HRM in 2:length(fname_Human_RM)\n",
    "    fname_in = @sprintf(\"../mpl/aa_csv/CH848/%s-poly.csv\", fname_Human_RM[i_HRM])\n",
    "    csv_poly = DataFrame(CSV.File( fname_in));\n",
    "    append!(list_set_HXB2, copy(csv_poly.HXB2))\n",
    "    append!(list_set_PRO, copy(csv_poly.PRO))\n",
    "    append!(list_set_date, copy(csv_poly.date))\n",
    "    append!(list_set_mutation, copy(csv_poly.mutation))\n",
    "    append!(list_set_reversion, copy(csv_poly.reversion))\n",
    "    append!(list_set_RMs, [fname_Human_RM[i_HRM] for _ in 1:length(csv_poly.HXB2)] )\n",
    "    append!(list_set_s_MPL, copy(csv_poly.s_MPL))\n",
    "    glycan_plus_temp = zeros(length(csv_poly.glycan_plus)); glycan_plus_temp[csv_poly.glycan_plus] .= 1\n",
    "    glycan_minus_temp = zeros(length(csv_poly.glycan_minus)); glycan_minus_temp[csv_poly.glycan_minus] .= 1\n",
    "    glycan_shift_temp = zeros(length(csv_poly.glycan_plus)); glycan_shift_temp[csv_poly.glycan_plus .* csv_poly.glycan_minus] .= 1\n",
    "    append!(list_set_N_plus, copy(glycan_plus_temp))\n",
    "    append!(list_set_N_minus, copy(glycan_minus_temp))\n",
    "    append!(list_set_N_shift, copy(glycan_shift_temp))\n",
    "    append!(list_set_CD4BS, copy(csv_poly.CD4BS))\n",
    "    append!(list_set_LD, copy(csv_poly.LD))\n",
    "    append!(list_set_V1, copy(csv_poly.V1))\n",
    "    append!(list_set_V2, copy(csv_poly.V2))\n",
    "    append!(list_set_V3, copy(csv_poly.V3))\n",
    "    append!(list_set_V4, copy(csv_poly.V4))\n",
    "    append!(list_set_V5, copy(csv_poly.V5));\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort selection coefficients.\n",
    "sort_indx = sortperm(list_set_s_MPL, rev=true);\n",
    "\n",
    "df = DataFrame(\n",
    "    HXB2_index = list_set_HXB2[sort_indx], \n",
    "    RM = list_set_RMs[sort_indx], \n",
    "    reversion = list_set_reversion[sort_indx], \n",
    "    mutation = list_set_mutation[sort_indx], \n",
    "    PRO = list_set_PRO[sort_indx],\n",
    "    date = list_set_date[sort_indx], \n",
    "    s_MPL = list_set_s_MPL[sort_indx], \n",
    "    N_linked_glycan_plus_fr3 = list_set_N_plus[sort_indx], \n",
    "    N_linked_glycan_minus_fr3 = list_set_N_minus[sort_indx], \n",
    "    N_linked_glycan_shift_fr3 = list_set_N_shift[sort_indx], \n",
    "    LoopD = list_set_LD[sort_indx], \n",
    "    V1 = list_set_V1[sort_indx], \n",
    "    V2 = list_set_V2[sort_indx], \n",
    "    V3 = list_set_V3[sort_indx], \n",
    "    V4 = list_set_V4[sort_indx], \n",
    "    V5 = list_set_V5[sort_indx], \n",
    "    # The following is just copying other result to avoid error due to the absent of the process\n",
    "    CD4BS = list_set_CD4BS[sort_indx], \n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"../out/summary-RMs-AA_CH848.csv\", df); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making enrichment values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../src/process_HIV_mutation_for_CSV.jl\") ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CH505 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N_null_temp_all, N_null_all, N_sel_all) = (16094, 16094, 1433)\n",
      "(n_null_LD, N_null_LD_all) = (171, 16094)\n",
      "(n_null_V1, N_null_V1_all) = (323, 16094)\n",
      "(n_null_V2, N_null_V2_all) = (760, 16094)\n",
      "(n_null_V3, N_null_V3_all) = (665, 16094)\n",
      "(n_null_V4, N_null_V4_all) = (646, 16094)\n",
      "(n_null_V5, N_null_V5_all) = (171, 16094)\n",
      "N_null_N_glycan_all = 1433\n",
      "n_null_N_add = 26\n",
      "n_null_N_rem = 243\n",
      "n_null_N_sht = 15\n",
      "n_null_N_any = 254\n",
      "n_null_rev = 122\n",
      "N_null_rev_all = 16094\n"
     ]
    }
   ],
   "source": [
    "#csv_index_and_TF= DataFrame(CSV.File(\"../data/mpl/703010505-3-index.csv\"));\n",
    "csv_index_and_TF= DataFrame(CSV.File(\"../mpl/aa_csv/CH505/index-703010505.csv\"));\n",
    "\n",
    "csv_raw_SHIV_CH505 = DataFrame(CSV.File(\"../out/summary-RMs-AA_CH505.csv\"));\n",
    "\n",
    "categories = [\"Rev.\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"LD\", \"CD4\", \"PNG-shield\", \"PNG-holse\", \"PNG-shift\", \"PNG\"];\n",
    "\n",
    "α_threshold_RMs_set = sort([ [0.01 * i for i in 1:9]; [0.1 * i for i in 1:10] ], rev=true)\n",
    "\n",
    "\n",
    "(x_fold_summary, log_P, α_summary, n_fold_summary, types_summary) = get_enrichment_and_pvalues_AA(csv_raw_SHIV_CH505, csv_index_and_TF, α_threshold_RMs_set);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(\n",
    "    categories=types_summary,\n",
    "    fraction=[@sprintf(\"%.3f\",x) for x in α_summary],\n",
    "    num_cutoff=Int.(n_fold_summary),\n",
    "    enrichment=x_fold_summary,\n",
    "    log10_P = log_P\n",
    ")\n",
    "CSV.write(\"../out/enrichment_SHIV-CH505_multiply_fraction_AA.csv\", df);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CH848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N_null_temp_all, N_null_all, N_sel_all) = (16474, 16474, 2000)\n",
      "(n_null_LD, N_null_LD_all) = (171, 16474)\n",
      "(n_null_V1, N_null_V1_all) = (627, 16474)\n",
      "(n_null_V2, N_null_V2_all) = (798, 16474)\n",
      "(n_null_V3, N_null_V3_all) = (665, 16474)\n",
      "(n_null_V4, N_null_V4_all) = (532, 16474)\n",
      "(n_null_V5, N_null_V5_all) = (209, 16474)\n",
      "N_null_N_glycan_all = 2000\n",
      "n_null_N_add = 46\n",
      "n_null_N_rem = 359\n",
      "n_null_N_sht = 15\n",
      "n_null_N_any = 390\n",
      "n_null_rev = 116\n",
      "N_null_rev_all = 16474\n"
     ]
    }
   ],
   "source": [
    "#csv_index_and_TF= DataFrame(CSV.File(\"../data/mpl/703010848-3-index.csv\"));\n",
    "csv_index_and_TF= DataFrame(CSV.File(\"../mpl/aa_csv/CH848/index-703010848.csv\"));\n",
    "\n",
    "csv_raw_SHIV_CH848 = DataFrame(CSV.File(\"../out/summary-RMs-AA_CH848.csv\"));\n",
    "\n",
    "categories = [\"Rev.\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"LD\", \"CD4\", \"PNG-shield\", \"PNG-holse\", \"PNG-shift\", \"PNG\"];\n",
    "\n",
    "α_threshold_RMs_set = sort([ [0.01 * i for i in 1:9]; [0.1 * i for i in 1:10] ], rev=true)\n",
    "\n",
    "\n",
    "(x_fold_summary, log_P, α_summary, n_fold_summary, types_summary) = get_enrichment_and_pvalues_AA(csv_raw_SHIV_CH848, csv_index_and_TF, α_threshold_RMs_set);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(\n",
    "    categories=types_summary,\n",
    "    fraction=[@sprintf(\"%.3f\",x) for x in α_summary],\n",
    "    num_cutoff=Int.(n_fold_summary),\n",
    "    enrichment=x_fold_summary,\n",
    "    log10_P = log_P\n",
    ")\n",
    "CSV.write(\"../out/enrichment_SHIV-CH848_multiply_fraction_AA.csv\", df);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check glycan distribution on sequences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"enrichment_CH505 = DataFrame(CSV.File(\\\"../out/enrichment_CH505_multiply_fraction.csv\\\"));\\nenrichment_SHIVCH505 = DataFrame(CSV.File(\\\"../out/enrichment_grouped_SHIV_CH505_multiply_fraction.csv\\\"));\\n\\nenrichment_CH848 = DataFrame(CSV.File(\\\"../out/enrichment_CH848_multiply_fraction.csv\\\"));\\nenrichment_SHIVCH848 = DataFrame(CSV.File(\\\"../out/enrichment_grouped_SHIV_CH848_multiply_fraction.csv\\\"));\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "enrichment_CH505 = DataFrame(CSV.File(\"../out/enrichment_CH505_multiply_fraction.csv\"));\n",
    "enrichment_SHIVCH505 = DataFrame(CSV.File(\"../out/enrichment_grouped_SHIV_CH505_multiply_fraction.csv\"));\n",
    "\n",
    "enrichment_CH848 = DataFrame(CSV.File(\"../out/enrichment_CH848_multiply_fraction.csv\"));\n",
    "enrichment_SHIVCH848 = DataFrame(CSV.File(\"../out/enrichment_grouped_SHIV_CH848_multiply_fraction.csv\"));\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field_key_list = [\"Reversion\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"LD\", \"CD4BS\"]\n",
    "#field_key_list2 = [\"PNG\", \"Shield\", \"Hole\", \"Shift\"]\n",
    "#field_key_list = [\"Reversion\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"LD\", \"CD4BS\"]\n",
    "#field_key_list2 = [\"PNG\", \"Shield\", \"Hole\", \"Shift\"]\n",
    "\n",
    "#field_key_list = [\"Reversion\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"LD\", \"CD4BS\"]\n",
    "#field_key_list2 = [\"PNG\", \"Shield\", \"Hole\", \"Shift\"]\n",
    "#field_key_list = [\"Reversion\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"LD\", \"CD4BS\"]\n",
    "#field_key_list2 = [\"PNG\", \"Shield\", \"Hole\", \"Shift\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
